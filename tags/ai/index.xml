<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>ai on 유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?</title>
		<link>https://pko89403.github.io/tags/ai/</link>
		<description>Recent content in ai on pko89403.github.io</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>© Copyright notice | Vitae theme for Hugo</copyright>
		<lastBuildDate>Sun, 09 May 2021 19:05:20 +0900</lastBuildDate>
		
		<atom:link href="https://pko89403.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
			<link>https://pko89403.github.io/post/bert/</link>
			<pubDate>Sun, 09 May 2021 19:05:20 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/bert/</guid>
			<description>
			
				BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding 리뷰 Abstract BERT라고 부르는 언어 표현 모델을 소개한다. BERT는 Bidirectional …
			
			</description>
		</item>
		<item>
			<title>GPT2 : Language Models are Unsupervised Multitask Learners</title>
			<link>https://pko89403.github.io/post/gpt2/</link>
			<pubDate>Sat, 24 Apr 2021 09:33:15 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/gpt2/</guid>
			<description>
			
				Language Models are Unsupervised Multitask Learners  Language Model 이란?
 언어를 모델링 하기 위해 단어 시퀀스(문장)에 확률을 할당 하는 모델 ( m 개의 단어 시퀀스가 나타날 확률) …
			
			</description>
		</item>
		
	</channel>
</rss>
