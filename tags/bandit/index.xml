<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bandit on 유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?</title>
    <link>https://pko89403.github.io/tags/bandit/</link>
    <description>Recent content in Bandit on 유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© Copyright notice | [Vitae](https://github.com/dataCobra/hugo-vitae) theme for [Hugo](https://gohugo.io)</copyright>
    <lastBuildDate>Sat, 13 Nov 2021 16:05:55 +0900</lastBuildDate><atom:link href="https://pko89403.github.io/tags/bandit/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>밴딧 추천 오픈소스 OBP의 Bandit Policy 에 대한 설명 : Policy</title>
      <link>https://pko89403.github.io/post/ope_policy/</link>
      <pubDate>Sat, 13 Nov 2021 16:05:55 +0900</pubDate>
      
      <guid>https://pko89403.github.io/post/ope_policy/</guid>
      <description>밴딧 추천 오픈소스 OBP(Open Bandit Pipeline)의 Bandit Policy 최근에 밴딧 기반 추천에 관심을 가지고 스터디에 참여하는 등의 활동을 진행하고 있다.
밴딧 기반 추천 시스템 도메인을 위해 일본의 패션 이커머스 플랫폼 ZOZOTOWN 에서 Open Bandit Dataset 라고 하는 수집된 데이터셋을 공개를 했다. 이 데이터셋은 동일한 플랫폼에서 각기 다른 정책을 동작 시키면서 수집된 많은 밴딧 피드백 로그 셋을 가지는 차별점이 있고 결론적으로 서로 다른 OPE 예측기들의 실험적 비교를 최초로 할 수 있게 해주었다.</description>
    </item>
    
    <item>
      <title>밴딧 추천 오픈소스 OBP의 Off-Policy-Evaluation 에 대한 설명 : Off-Policy Evaluation</title>
      <link>https://pko89403.github.io/post/ope_offpolicy/</link>
      <pubDate>Sat, 13 Nov 2021 16:05:47 +0900</pubDate>
      
      <guid>https://pko89403.github.io/post/ope_offpolicy/</guid>
      <description>&amp;ldquo;밴딧 추천 오픈소스 OBP의 Off-Policy-Evaluation 에 대한 설명 : Off-Policy Evaluation&amp;rdquo; Bandit 추천의 기반인 Policy에 대해 알아봤고 오프라인으로 로깅된 밴딧 피드백을 이용해 Policy의 값을 추정하는 추정기들과 그 추정기를 검증하는 Offline-Policy-Evaluation에 대해 실습을 진행한다. 아래의 공식 예제 코드를 약간 변형해서 진행하게 된다.
실습 진행 예제 코드
전체 코드의 실습은 OBP에서 지원하는 아래의 항목들을 사용했다.
 Dataset : SyntheticDataset (제공하는 랜덤 데이터셋 ) Policy : LinUCB Evaluation : RM, IPW  SyntheticBanditDataset을 온라인 밴딧 알고리즘의 OPE를 검증에 사용한다.</description>
    </item>
    
    <item>
      <title>A Contextual-Bandit Algorithm for Mobile Context-Aware Recommender System 논문 리뷰</title>
      <link>https://pko89403.github.io/post/mcrs/</link>
      <pubDate>Sun, 11 Jul 2021 22:04:33 +0900</pubDate>
      
      <guid>https://pko89403.github.io/post/mcrs/</guid>
      <description>Abastract 모바일 맥락 기반 추천 시스템의 대부분의 접근 방법은 맥락 정보를 활용해서 유저와 관련성 있는 아이템을 추천하는데 초점이 맞춰져 있다. 고려할만한 맥락 정보로 아래 세가지가 있다.
 시간 위치 소셜 정보  이전의 연구들은 모두 유저의 컨텐츠 변화 문제를 고려하지 않는데 이 논문은 컨텐츠에 대해 변화하는
 유저의 흥미를 다이나믹하게 처리하는 알고리즘을 제시 유저 상황에 따라 Exploration과 Exploitation을 결정한 뒤 적응형으로 EE 트레이드 오프  직접 설계한 오프라인 시뮬레이션 프레임워크로 실제 온라인 로그 데이터에서 검증을 수행한다.</description>
    </item>
    
  </channel>
</rss>
