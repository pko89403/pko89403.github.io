<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Recommendation on 유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?</title>
		<link>https://pko89403.github.io/categories/recommendation/</link>
		<description>Recent content in Recommendation on pko89403.github.io</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>© Copyright notice | Vitae theme for Hugo</copyright>
		<lastBuildDate>Wed, 09 Mar 2022 20:45:24 +0900</lastBuildDate>
		
		<atom:link href="https://pko89403.github.io/categories/recommendation/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>GraphRec : Graph Neural Networks for Social Recommendation 리뷰</title>
			<link>https://pko89403.github.io/post/graphrec/</link>
			<pubDate>Wed, 09 Mar 2022 20:45:24 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/graphrec/</guid>
			<description>
			
				ABSTRACT 소셜 추천 시스템의 데이터는 아래와 같은 표현 된다.
 유저 - 유저 소셜 그래프 유저 - 아이템 그래프  그리고 핵심은 유저와 아이템의 Latent Factor로 학습하는 것이다.
그러나, GNNs으로 소셜 추천 시스템을 구축하는 것 …
			
			</description>
		</item>
		<item>
			<title>GMCF : Neural Graph Matching based Collaborative Filtering 리뷰</title>
			<link>https://pko89403.github.io/post/gmcf/</link>
			<pubDate>Wed, 09 Mar 2022 20:23:09 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/gmcf/</guid>
			<description>
			
				ABSTRACT 유저와 아이템의 어트리뷰트 들은 필수적인 사이드 정보이다. 본 논문에서는 기존 모델들이 구분하지 못하는 두 가지 어트리뷰트 상호작용을 발견했다.
 inner attribute interactions : …
			
			</description>
		</item>
		<item>
			<title>밴딧 추천 오픈소스 OBP의 Bandit Policy 에 대한 설명 : Policy</title>
			<link>https://pko89403.github.io/post/ope_policy/</link>
			<pubDate>Sat, 13 Nov 2021 16:05:55 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/ope_policy/</guid>
			<description>
			
				밴딧 추천 오픈소스 OBP(Open Bandit Pipeline)의 Bandit Policy 최근에 밴딧 기반 추천에 관심을 가지고 스터디에 참여하는 등의 활동을 진행하고 있다. …
			
			</description>
		</item>
		<item>
			<title>밴딧 추천 오픈소스 OBP의 Off-Policy-Evaluation 에 대한 설명 : Off-Policy Evaluation</title>
			<link>https://pko89403.github.io/post/ope_offpolicy/</link>
			<pubDate>Sat, 13 Nov 2021 16:05:47 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/ope_offpolicy/</guid>
			<description>
			
				“밴딧 추천 오픈소스 OBP의 Off-Policy-Evaluation 에 대한 설명 : Off-Policy Evaluation” Bandit 추천의 기반인 Policy에 대해 알아봤고 오프라인으로 로깅된 밴딧 피드백을 이용해 Policy의 값을 추정하 …
			
			</description>
		</item>
		<item>
			<title>A Contextual-Bandit Algorithm for Mobile Context-Aware Recommender System 논문 리뷰</title>
			<link>https://pko89403.github.io/post/mcrs/</link>
			<pubDate>Sun, 11 Jul 2021 22:04:33 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/mcrs/</guid>
			<description>
			
				Abastract 모바일 맥락 기반 추천 시스템의 대부분의 접근 방법은 맥락 정보를 활용해서 유저와 관련성 있는 아이템을 추천하는데 초점이 맞춰져 있다. 고려할만한 맥락 정보로 아래 세가지가 있다. …
			
			</description>
		</item>
		<item>
			<title>Collaborative Filtering Bandits 논문 리뷰</title>
			<link>https://pko89403.github.io/post/cofiba/</link>
			<pubDate>Sun, 27 Jun 2021 23:28:24 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/cofiba/</guid>
			<description>
			
				Collaborative Filtering Bandits 리뷰 ABSTRACT 기존 추천 방식
 Collaborative filtering Content-Based Filtering  주어진 학습 데이터로 부터 모델을 학습하는 메소드( …
			
			</description>
		</item>
		<item>
			<title>단단한 강화 학습 2장 다중 선택 2.6 ~ 정리</title>
			<link>https://pko89403.github.io/post/rl2.5.2/</link>
			<pubDate>Sun, 20 Jun 2021 22:11:13 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/rl2.5.2/</guid>
			<description>
			
				단단한 강화 학습 2장 다중 선택 2.6 ~ 정리 2.6 Optimal Initial Value Exploration을 촉진하는 기법을 긍정적 초깃값(Optimal initial value)라고 부른다. …
			
			</description>
		</item>
		<item>
			<title>단단한 강화 학습 2장 다중 선택 ~ 2.5 정리</title>
			<link>https://pko89403.github.io/post/rl2.5/</link>
			<pubDate>Sun, 13 Jun 2021 22:26:04 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/rl2.5/</guid>
			<description>
			
				Bandit Problem은 오직 하나의 상태만 다루는 강화학습 문제이다.
강화 학습은 지도 학습과는 다른 종류의 학습 피드백을 전달한다. 학습자의 행동과 무관하게 정해져 있는 정답이 있는 지도 학습과는 다르게, 강화 학습은 행동에 대한 결과를 피드백 …
			
			</description>
		</item>
		<item>
			<title>Artwork Personalization at Netflix</title>
			<link>https://pko89403.github.io/post/netflixartwork2/</link>
			<pubDate>Sun, 06 Jun 2021 22:41:41 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/netflixartwork2/</guid>
			<description>
			
				Artwork Personalization at Netflix 넷플릭스의 아트워크 추천에 대해서 알아보자. 블로그, PPT, 유튜브 자료가 있다.
Artwork Personalization at Netflix …
			
			</description>
		</item>
		
	</channel>
</rss>
