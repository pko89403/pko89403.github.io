<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Recommendation on 유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?</title>
		<link>https://pko89403.github.io/categories/recommendation/</link>
		<description>Recent content in Recommendation on pko89403.github.io</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>© Copyright notice | Vitae theme for Hugo</copyright>
		<lastBuildDate>Sun, 11 Jul 2021 22:04:33 +0900</lastBuildDate>
		
		<atom:link href="https://pko89403.github.io/categories/recommendation/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>A Contextual-Bandit Algorithm for Mobile Context-Aware Recommender System 논문 리뷰</title>
			<link>https://pko89403.github.io/post/mcrs/</link>
			<pubDate>Sun, 11 Jul 2021 22:04:33 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/mcrs/</guid>
			<description>
			
				Abastract 모바일 맥락 기반 추천 시스템의 대부분의 접근 방법은 맥락 정보를 활용해서 유저와 관련성 있는 아이템을 추천하는데 초점이 맞춰져 있다. 고려할만한 맥락 정보로 아래 세가지가 있다. …
			
			</description>
		</item>
		<item>
			<title>Collaborative Filtering Bandits 논문 리뷰</title>
			<link>https://pko89403.github.io/post/cofiba/</link>
			<pubDate>Sun, 27 Jun 2021 23:28:24 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/cofiba/</guid>
			<description>
			
				Collaborative Filtering Bandits 리뷰 ABSTRACT 기존 추천 방식
 Collaborative filtering Content-Based Filtering  주어진 학습 데이터로 부터 모델을 학습하는 메소드( …
			
			</description>
		</item>
		<item>
			<title>단단한 강화 학습 2장 다중 선택 2.6 ~ 정리</title>
			<link>https://pko89403.github.io/post/rl2.5.2/</link>
			<pubDate>Sun, 20 Jun 2021 22:11:13 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/rl2.5.2/</guid>
			<description>
			
				단단한 강화 학습 2장 다중 선택 2.6 ~ 정리 2.6 Optimal Initial Value Exploration을 촉진하는 기법을 긍정적 초깃값(Optimal initial value)라고 부른다. …
			
			</description>
		</item>
		<item>
			<title>단단한 강화 학습 2장 다중 선택 ~ 2.5 정리</title>
			<link>https://pko89403.github.io/post/rl2.5/</link>
			<pubDate>Sun, 13 Jun 2021 22:26:04 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/rl2.5/</guid>
			<description>
			
				Bandit Problem은 오직 하나의 상태만 다루는 강화학습 문제이다.
강화 학습은 지도 학습과는 다른 종류의 학습 피드백을 전달한다. 학습자의 행동과 무관하게 정해져 있는 정답이 있는 지도 학습과는 다르게, 강화 학습은 행동에 대한 결과를 피드백 …
			
			</description>
		</item>
		<item>
			<title>Artwork Personalization at Netflix</title>
			<link>https://pko89403.github.io/post/netflixartwork2/</link>
			<pubDate>Sun, 06 Jun 2021 22:41:41 +0900</pubDate>
			
			<guid>https://pko89403.github.io/post/netflixartwork2/</guid>
			<description>
			
				Artwork Personalization at Netflix 넷플릭스의 아트워크 추천에 대해서 알아보자. 블로그, PPT, 유튜브 자료가 있다.
Artwork Personalization at Netflix …
			
			</description>
		</item>
		
	</channel>
</rss>
