<!DOCTYPE html>
<html lang="en"><head>
	
	<meta name="generator" content="Hugo 0.82.1" />
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	
	<meta property="og:title" content="Graph Neural Networks에 대한 이해">
	
	
	<meta name="keywords" content="ai,graph,gnn,gcn,graphsage,deepwalk"><meta name="description" content="GNN 기반 추천 논문들을 읽기 전에 정리를 해보았다. 기본은 A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage) …"><meta property="og:title" content="Graph Neural Networks에 대한 이해" />
<meta property="og:description" content="GNN 기반 추천 논문들을 읽기 전에 정리를 해보았다. 기본은 A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)에 대한 내용 번역이고 추가로 정리한 내용들을 포함했다.
GNN은 그래프에서 노드 간의 종속성을 모델링하는 능력을 가지고 있다! 관계, 상호 작용과 같은 추상적인 개념을 다루기 적합해서 관계를 분석할 필요가 있을 때 기초적으로 사용할 수 있다.
Basics of Graph Neural Network 그래프 G는 노드라고 부르는 버텍스의 집합 V 그리고 엣지의 집합 E로 간단하게 설명할 수 있다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://pko89403.github.io/post/gnn_intro/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-09-23T23:53:37&#43;09:00" />
<meta property="article:modified_time" content="2021-09-23T23:53:37&#43;09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Graph Neural Networks에 대한 이해"/>
<meta name="twitter:description" content="GNN 기반 추천 논문들을 읽기 전에 정리를 해보았다. 기본은 A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)에 대한 내용 번역이고 추가로 정리한 내용들을 포함했다.
GNN은 그래프에서 노드 간의 종속성을 모델링하는 능력을 가지고 있다! 관계, 상호 작용과 같은 추상적인 개념을 다루기 적합해서 관계를 분석할 필요가 있을 때 기초적으로 사용할 수 있다.
Basics of Graph Neural Network 그래프 G는 노드라고 부르는 버텍스의 집합 V 그리고 엣지의 집합 E로 간단하게 설명할 수 있다."/>
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
	<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
	<link rel="stylesheet" type="text/css" media="screen" href="/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="/css/all.css" />
	<link rel="stylesheet" href="/css/katex.min.css" crossorigin="anonymous">
	<script defer src="/js/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
	<script defer src="/js/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
	<script>
		document.addEventListener("DOMContentLoaded", function() {
			renderMathInElement(document.body, {
				delimiters: [
					{left: "$$", right: "$$", display: true},
					{left: "$", right: "$", display: false}
				]
		});
		});
	</script><title>Graph Neural Networks에 대한 이해 | 유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?</title>


</head>
<body><header>
	
	<div id="avatar">
		<a href="https://pko89403.github.io/">
		  <img src="/img/Avatar.png" alt="유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?">
		</a>
	</div>
	
	<div id="titletext"><h2 id="title"><a href="https://pko89403.github.io/">유기농은 너무 비싸서 그런데 농약 친 건 어딨나요?</a></h2></div>
	<div id="title-description"><p id="subtitle"><a href=""></a></p><div id="social">
			<nav>
				<ul>
					<li><a href="https://github.com/pko89403"><i title="Github" class="icons fab fa-github"></i></a></li><li><a href="mailto:pko89403@gmail.com"><i title="Email" class="icons fas fa-envelope"></i></a></li></ul>
			</nav>
		</div>
	</div>
	
	<div id="mainmenu">
		<nav>
			<ul>
				
				<li><a href="/">Home</a></li>
				
				<li><a href="/post">All Posts</a></li>
				
				<li><a href="/about">About</a></li>
				
				<li><a href="/tags">Tags</a></li>
				
				<li><a href="/categories">Categories</a></li>
				
			</ul>
		</nav>
	</div>
	
</header>
<main><div class="post">
	
	<div class="author">
	
	</div>
	<div class="post-header">
	
		<div class="meta">
			
			<div class="date">
				<span class="day">23</span>
				<span class="rest">Sep 2021</span>
			</div>
			
		</div>
		
		<div class="matter">
			<h1 class="title">Graph Neural Networks에 대한 이해</h1>
		</div>
	</div>
	<div class="markdown">
		<p>GNN 기반 추천 논문들을 읽기 전에 정리를 해보았다. 기본은 <a href="https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3" target="_blank">A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)</a>에 대한 내용 번역이고 추가로 정리한 내용들을 포함했다.</p>
<p>GNN은 그래프에서 노드 간의 종속성을 모델링하는 능력을 가지고 있다! 관계, 상호 작용과 같은 추상적인 개념을 다루기 적합해서 관계를 분석할 필요가 있을 때 기초적으로 사용할 수 있다.</p>
<h1 id="basics-of-graph-neural-network">Basics of Graph Neural Network</h1>
<p>그래프 G는 노드라고 부르는 버텍스의 집합 V 그리고 엣지의 집합 E로 간단하게 설명할 수 있다.</p>
<h3 id="g---v-e">$G = ( V, E)$</h3>
<p>그리고 GNN의 핵심은 특정 노드를 그 이웃 노드 와의 연결로 정의하는 것이다. 노드 간 연결 관계와 이웃 노드들의 상태를 활용해서 각 노드의 상태를 반복해서 업데이트하고 최종 업데이트 된 상태를 사용해서 원하는 태스크를 수행한다.</p>
<p>GNN을 사용한 대부분의 어플리케이션은 노드 분류 태스크를 한다. 기본적으로 그래프의 모든 노드는 라벨과 연결되어져 있고 우리는 노드의 레이블을 예측하려고 한다. 일부 노드가 라벨링 되어져있는 그래프 $G$가 주어지면, 레이블 된 노드를 활용해서 라벨링 되지 않은 노드 라벨을 예측하는 것을 목표로 한다.</p>
<h3 id="환경">환경</h3>
<ul>
<li>각각의 노드 $v$는 고유한 피처 $x_v$를 가지고 그라운드 트루스 라벨 $t_v$와 연결된다.</li>
<li>그래프 $G$ 중 일부 노드에만 라벨링이 되어있다.</li>
</ul>
<h3 id="목표">목표</h3>
<ul>
<li>라벨링 된 노드들을 활용해서 아직 라벨링 되지 않은 라벨을 예측해야한다.</li>
</ul>
<h3 id="학습">학습</h3>
<ul>
<li>각각의 노드를 자신의 이웃 노드의 정보를 가지는 $d$  차원의 벡터 $h_v$로 표현하도록 학습한다.</li>
</ul>
<p><strong>최종적으로 노드를 표현하는 상태를 노드 임베딩($h_v$)이라고 한다.</strong></p>
<h3 id="h_v--fx_v-x_cov-h_nev-x_nev">$h_v = f(x_v, x_{co[v]}, h_{ne[v]}, x_{ne[v]})$</h3>
<ul>
<li>$x_v$는 v의 피처를 의미한다.</li>
<li>$x_{co[v]}$는 $v$와 연결되어 있는 엣지의 피처를 의미한다.</li>
<li>$h_{ne[v]}$는 $v$와 연결된 이웃 노드의 임베딩을 의미한다.</li>
<li>$x_{ne[v]}$는 $v$와 완결된 이웃 노드의 피처들을 의미한다.</li>
<li>함수 $f$는 트랜지션 함수로 입력을 d 차원 공간으로 투영시킨다</li>
</ul>
<p>$h_v$에 <strong>Banach fixed theorem</strong>( 변수 x와 연속 함수 $f(x)$의 정의영역[$f(x)$의 정의역과 공역]이 닫힌 공간 $[0,1]$로 한정되면 $f(x_0) = x_0$ 인 고정점 $x_0$이 반드시 존재한다 )을 적용해서 반복적으로 업데이트 하도록 위 식을 재작성 할 수 있다. 이런 연산( 멀리 있는 노드로 부터 현재 노드 까지 정보가 전달 되는 과정 )을 &lsquo;message passing&rsquo; 이나 &lsquo;neighborhood aggregation&rsquo; 라고 한다.</p>
<h3 id="ht1---fht-x">$H^{t+1}  = F(H^t, X)$</h3>
<ul>
<li>$H$와 $X$가 모든 $h$와 $x$를 결합한 것을 의미한다.</li>
</ul>
<p>GNN의 결과는 출력 함수 $g$로 상태 $h_v$와 피처 $x_v$를 전달해서 결과값을 출력한다.</p>
<h3 id="o_v--gh_v-x_v">$o_v = g(h_v, x_v)$</h3>
<p>$f$와 $g$는 feed-forward fully-connected 네트워크다. L1 로스는 다음과 같이 공식화할 수 있다.</p>
<h3 id="loss--sum_i1pt_i---o_i">$loss = \sum_{i=1}^{p}(t_i - o_i)$</h3>
<p>마찬가지로 그래디언트 디센트 같은 방법으로 옵티마이즈 할 수 있다.</p>
<p>초기의 GNN은 세가지의 중요한 이슈가 있었고 이러한 이슈들을 해결하기 위해서 계속해서 발전하고 있다.</p>
<ol>
<li>&lsquo;Fixed Point&rsquo; 가정이 완화되면, MLP로 더 안정적인 표현을 학습하고 반복적인 업데이트 과정을 제거할 수 있다. 원래 제안 방법에서는 반복 시, 전이 함수 $f$에 동일한 파라미터를 사용했지만, 서로 다른 MLP 레이어의 서로 다른 파라미터들은 계층적 피처 추출을 허용하기 때문이다.</li>
<li>엣지 정보를 처리할 수 없음.</li>
<li>&lsquo;Fixed Point&rsquo;는 노드 분포의 다양성을 해칠 수 있어서 노드 들의 표현의 학습에 적절하지 않을 수 있다.</li>
</ol>
<h1 id="deepwalk">DeepWalk</h1>
<p>비지도 방식으로 노드 임베딩 학습을 제안한 첫번째 알고리즘. 워드 임베딩과 유사하다. 두가지 과정을 가진다.</p>
<ol>
<li>노드 시퀀스 생성을 위해서 노드에 랜덤 워크를 수행한다.</li>
<li>생성된 노드 시퀀스를 기반으로 Skip-Gram 방식으로 각 노드 임베딩을 학습한다.</li>
</ol>
<p>램덤 워크의 각 타임 스탬프에서 다음 노드는 이전 노드의 이웃 중 유니폼하게 샘플링된다. 논문에서는 노드의 수가 많기 때문에 소프트맥스의 연산량을 해결하기 위해서 계층적 소프트맥스를 적용했다.</p>
<p>딥워크 GNN이 학습되면 모델은 각 노드에 대한 표현을 학습하게 된다. 그러나 &lsquo;일반성이 부족하다&rsquo;는 이슈가 있다. 새로운 노드가 추가되면, 새로운 노드를 표현하기 위해서 모델을 재학습 해야한다. 그래프의 노드가 계속해서 변화하는 다이나믹 그래프에는 적합하지 않다.</p>
<h1 id="graph-convolutional-networks">Graph Convolutional Networks</h1>
<p>노드와 노드의 이웃 노드 정보를 이미지의 각 픽셀에 대한 주변 정보를 캡처하는 컨볼루션 신경망을 사용해서 캡처한다. GCN 모델이  거대해 질수록 그래프에서 더 추상적인 피처를 뽑아낼 수 있다. 일반적으로 그래프의 노드 간 연결이 표현된 인접 행렬과 노드의 피처 행렬을 입력으로 받는다.</p>
<ul>
<li>
<p>노드 피처를 업데이트 하기 위해서 노드의 피처와 이웃 노드들의 정보를 이용한다.</p>
<p>$f(H^i, A) = \sigma(AH^iW^i)$</p>
<ul>
<li>$A$는 인접 행렬을 의미한다.</li>
<li>$W^i$는 i번째 레이어의 가중치 매트릭스로 그래프에 있는 노드 전체에 적용된다.(Weight Sharing)</li>
</ul>
</li>
<li>
<p>이웃 노드와의 연결 만을 고려한다면 해당 노드 자체에 대한 정보가 노드 임베딩에 포함 되지 않아 self-loop를 추가한다</p>
<p>$\tilde{A} = A + I$</p>
</li>
<li>
<p>인접 행렬인 A가 정규화 되어있지 않으면 피처 벡터를 곱하는 경우 불안정할 수 있다. 따라서 $A$를 정규화 한다.</p>
<p>$\tilde{A} = D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$</p>
<ul>
<li>$D$는 $A$의 차수 행렬(Degree)을 의미한다.</li>
</ul>
</li>
</ul>
<p>GCN은 크게 두 알고리즘으로 분류 될 수 있다.</p>
<h2 id="spatial-convolutional-network">Spatial Convolutional Network</h2>
<p>그래프 위에 컨볼루션 연산을 공간 기반으로 직접 적용하는 방식이다. 컨볼루션의 고정된 크기의 필터를 사용한다. 따라서 고정된 이웃 노드에서만 정보를 받아서 노드의 정보를 업데이트한다.</p>
<h2 id="spectral-convolutional-network">Spectral Convolutional Network</h2>
<p>신호 처리 분야에서 영감을 받은 알고리즘이다. 노드 간 정보 전파를 신호 전달로 고려한다. 그래프를 노멀라이즈한 라플라시안 매트릭스로 표현 한 후에 &lsquo;Spectral-based&rsquo; 라는 스펙트럼에 기반한 한 컨볼루션을 그래프에 적용해서 그래프를 표현한다.</p>
<h1 id="graphsage">GraphSage</h1>
<p>그래프 세이지는 각 노드 임베딩을 귀납적인 방식으로 학습해서 딥워크가 가진 문제에 대한 솔루션을 제공한다. 각각의 노드가 자신의 이웃에 대한 집계 결과로 표현된다. 따라서 학습 중에 그래프에 포함되어 있지 않았던 노드도 그 노드의 이웃 노드 들로 표현될 수 있다. GCN과의 차이점은 GraphSage는 셀프와 이웃이 CONCAT 된다는 점이고 GCN은 SUM이 된다는 점이 다르다.</p>
<figure>
    <img src="/images/gnn/gnn0.png"/> 
</figure>

<ul>
<li>2번 줄 :  총 $k$ 횟수 만큼 업데이트를 진행한다.</li>
<li>5번 줄 : $h^k_v$ 는 집계 함수를 사용해서 업데이트 된다. 업데이트에는 이전 스텝의 $v$의 벡터, 이전 스텝의 $v$의 이웃에 대한 벡터 집계 그리고 가중치 매트릭스 $W^k$를 사용한다.</li>
</ul>
<p>논문에서는 세가지 집계 함수를 제시한다.</p>
<h2 id="1-mean-aggregator">1. Mean aggregator</h2>
<p>노드 벡터와 그 노드의 이웃 노드의 벡터에 평균을 취한다.</p>
<figure>
    <img src="/images/gnn/gnn1.png"/> 
</figure>

<p>원래 연산과 비교하면 5번 줄의 CONCAT 연산이 제거 되었는데 이 연산은 &ldquo;skip-connection&quot;으로 볼 수 도 있다.</p>
<h2 id="2-lstm-aggregator">2. LSTM aggregator</h2>
<p>그래프 노드들 간에 정해진순서가 없어서 순서를 랜덤하게 할당한 후에 LSTM을 적용한다.</p>
<h2 id="3-pooling-aggregator">3. Pooling aggregator</h2>
<p>노드의 이웃 노드 셋에 엘리먼트 별 풀링 함수를 수행한다.</p>
<figure>
    <img src="/images/gnn/gnn2.png"/> 
</figure>

<p>풀링은 평균 등의 다른 풀링 함수로 교체될 수 있다. 논문에서는 맥스 풀링을 디폴트로 사용한다. 로스 함수는 다음과 같이 정의되고 가까운 노드가 유사한 임베딩을 가지고 멀리 떨어진 노드는 투영된 공간에서 분리되도록 한다.</p>
<figure>
    <img src="/images/gnn/gnn3.png"/> 
</figure>

<ul>
<li>$u$와 $v$는 고정된 길이의 랜덤 워크에서 동시에 등장한다.</li>
<li>$v_n$은 $u$와 동시에 등장 하지 않는 네거티브 샘플 들이다.</li>
</ul>
<h1 id="graph-attention-network">Graph Attention Network</h1>
<p>셀프 어텐션 개념을 그래프 구조의 데이터에 적용한 방법. 같은 이웃 노드 셋에 가중치를 다르게 준다. 전체 그래프에 대한 접근이 없이 학습이 가능하다.</p>
<h1 id="graph-isomorphism-networks">Graph Isomorphism Networks</h1>
<p>GCN과 GraphSage 에서의 aggregation의 과정이 injective(일대일)이 아닌 경우가 있다.(서로 다른 엘리먼트로 구분을 못한다. ) 이러한 한계를 해결하기 위한 솔루션으로 sum aggregation을 사용해서 그래프의 구조적인 차이를 파악하는 새로운 그래프 뉴럴 네트워크 구조를 제안했다.</p>
<h1 id="참고-사이트">참고 사이트</h1>
<p><a href="https://ghebook.blogspot.com/2011/10/fixed-point-theorem.html" target="_blank">고정점 정리(固定點 定理, Fixed Point Theorem)</a></p>
<p><a href="https://medium.com/watcha/gnn-%EC%86%8C%EA%B0%9C-%EA%B8%B0%EC%B4%88%EB%B6%80%ED%84%B0-%EB%85%BC%EB%AC%B8%EA%B9%8C%EC%A7%80-96567b783479" target="_blank">GNN 소개 - 기초부터 논문까지</a></p>
<p><a href="https://greeksharifa.github.io/machine_learning/2021/06/05/GIN/" target="_blank">Python, Machine &amp;amp; Deep Learning</a></p>

	</div>
	
	
	
	
	
	
	
	<div class="tags">
		<div class="taxosfloating_left">
			<p>Categories</p>
		</div>
		<div class="termsfloating_right">
			<p>
			
			
			
			<a href="/categories/gnn/"> gnn </a>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			</p>
		</div>
		<div class="clearit"></div>
		
		
		
		
	
		
	
	
	
	<div class="tags">
		<div class="taxosfloating_left">
			<p>Tags</p>
		</div>
		<div class="termsfloating_right">
			<p>
			
			
			
			<a href="/tags/ai/"> ai </a>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<a href="/tags/deepwalk/"> deepwalk </a>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			<a href="/tags/gcn/"> gcn </a>
			
			
			
			
			
			<a href="/tags/gnn/"> gnn </a>
			
			
			
			
			
			
			
			
			
			<a href="/tags/graph/"> graph </a>
			
			
			
			
			
			<a href="/tags/graphsage/"> graphsage </a>
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			</p>
		</div>
		<div class="clearit"></div>
		
		
		
		
		
	</div>
<div id="disqus_thread"></div>
<script type="text/javascript">
	(function() {
	    
	    
	    if (window.location.hostname == "localhost")
	        return;
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    var disqus_shortname = 'Slave';
	    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>Please enable JavaScript to load the comments.</noscript>


</div>

  </main>
<footer>
	 © Copyright notice | <a href="https://github.com/dataCobra/hugo-vitae">Vitae</a> theme for <a href="https://gohugo.io">Hugo</a> 
	
	
	
</footer>


</body>
</html>
